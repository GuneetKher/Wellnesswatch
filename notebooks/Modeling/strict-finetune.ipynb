{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-10T08:33:57.001543Z",
     "iopub.status.busy": "2023-04-10T08:33:57.000730Z",
     "iopub.status.idle": "2023-04-10T08:34:21.177882Z",
     "shell.execute_reply": "2023-04-10T08:34:21.176578Z",
     "shell.execute_reply.started": "2023-04-10T08:33:57.001475Z"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "  import portalocker\n",
    "except ModuleNotFoundError:\n",
    "  !pip install portalocker\n",
    "  import portalocker\n",
    "update_torchtext = False\n",
    "try:\n",
    "  import torchtext\n",
    "  update_torchtext = torchtext.__version__ < \"0.15\"\n",
    "except ModuleNotFoundError:\n",
    "  update_torchtext = True\n",
    "if update_torchtext:\n",
    "  !pip uninstall --yes fastai\n",
    "  import re\n",
    "  cudaver = !nvcc --version | grep release\n",
    "  cudaver = re.search(r\".*release (.*),.*\", cudaver[0]).group(1)\n",
    "  print(f\"Found CUDA version {cudaver}\")\n",
    "  cudaver_nodot = cudaver.replace(\".\",\"\")\n",
    "  !pip install -U torch torchvision torchaudio \"torchtext>=0.15\" --index-url https://download.pytorch.org/whl/cu{cudaver_nodot}\n",
    "  !pip install tensorboardX lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-10T08:34:32.380375Z",
     "iopub.status.busy": "2023-04-10T08:34:32.379913Z",
     "iopub.status.idle": "2023-04-10T08:34:46.295122Z",
     "shell.execute_reply": "2023-04-10T08:34:46.293573Z",
     "shell.execute_reply.started": "2023-04-10T08:34:32.380336Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import tensorboardX\n",
    "# import torchtext.functional as F\n",
    "\n",
    "from transformers import AutoTokenizer, XLMRobertaForSequenceClassification,DataCollatorWithPadding,XLMRobertaTokenizerFast\n",
    "\n",
    "from IPython.display import Markdown\n",
    "import pandas as pd\n",
    "\n",
    "# DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-10T08:34:47.595396Z",
     "iopub.status.busy": "2023-04-10T08:34:47.594617Z",
     "iopub.status.idle": "2023-04-10T08:34:47.608826Z",
     "shell.execute_reply": "2023-04-10T08:34:47.607672Z",
     "shell.execute_reply.started": "2023-04-10T08:34:47.595349Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-10T08:34:47.620048Z",
     "iopub.status.busy": "2023-04-10T08:34:47.619178Z",
     "iopub.status.idle": "2023-04-10T08:34:48.742228Z",
     "shell.execute_reply": "2023-04-10T08:34:48.741208Z",
     "shell.execute_reply.started": "2023-04-10T08:34:47.619998Z"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "from torch.utils.data import DataLoader\n",
    "# dataset = DatasetDict.load_from_disk('ww-binary-dataset-small')\n",
    "dataset = DatasetDict.load_from_disk('ww-strict-binary-dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-10T08:34:48.744677Z",
     "iopub.status.busy": "2023-04-10T08:34:48.744016Z",
     "iopub.status.idle": "2023-04-10T08:35:09.592394Z",
     "shell.execute_reply": "2023-04-10T08:35:09.591398Z",
     "shell.execute_reply.started": "2023-04-10T08:34:48.744636Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/guneet/Documents/BD2/DataSIGNS/notebooks/Modeling/ww-strict-binary-dataset/train/cache-d16819e29be1b080.arrow\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "train_datapipe = dataset['train']\n",
    "val_datapipe = dataset['validation']\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "train_datapipe = train_datapipe.map(lambda x:  tokenizer(x['Text'],truncation=True,padding=True))\n",
    "val_datapipe = val_datapipe.map(lambda x:  tokenizer(x['Text'],truncation=True,padding=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-10T08:35:09.594645Z",
     "iopub.status.busy": "2023-04-10T08:35:09.594253Z",
     "iopub.status.idle": "2023-04-10T08:35:09.603465Z",
     "shell.execute_reply": "2023-04-10T08:35:09.602297Z",
     "shell.execute_reply.started": "2023-04-10T08:35:09.594601Z"
    }
   },
   "outputs": [],
   "source": [
    "train_datapipe.set_format(\"torch\")\n",
    "val_datapipe.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-10T08:35:09.605692Z",
     "iopub.status.busy": "2023-04-10T08:35:09.604837Z",
     "iopub.status.idle": "2023-04-10T08:35:09.622732Z",
     "shell.execute_reply": "2023-04-10T08:35:09.621644Z",
     "shell.execute_reply.started": "2023-04-10T08:35:09.605652Z"
    }
   },
   "outputs": [],
   "source": [
    "train_datapipe = train_datapipe.remove_columns(['Author', 'Title', 'Subreddit', 'Flair', 'Post ID', 'Url', 'Created Time',\"Text\"])\n",
    "val_datapipe = val_datapipe.remove_columns(['Author', 'Title', 'Subreddit', 'Flair', 'Post ID', 'Url', 'Created Time',\"Text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-10T08:35:09.624572Z",
     "iopub.status.busy": "2023-04-10T08:35:09.624215Z",
     "iopub.status.idle": "2023-04-10T08:35:09.636554Z",
     "shell.execute_reply": "2023-04-10T08:35:09.635563Z",
     "shell.execute_reply.started": "2023-04-10T08:35:09.624536Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['label', '__index_level_0__', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 16002\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_datapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-10T08:38:17.585692Z",
     "iopub.status.busy": "2023-04-10T08:38:17.584468Z",
     "iopub.status.idle": "2023-04-10T08:38:17.592258Z",
     "shell.execute_reply": "2023-04-10T08:38:17.591131Z",
     "shell.execute_reply.started": "2023-04-10T08:38:17.585647Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    train_datapipe, batch_size=8, \n",
    "    collate_fn=data_collator\n",
    ")\n",
    "eval_dataloader = DataLoader(\n",
    "    val_datapipe, batch_size=8, collate_fn=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-10T08:35:09.652226Z",
     "iopub.status.busy": "2023-04-10T08:35:09.651832Z",
     "iopub.status.idle": "2023-04-10T08:35:09.658425Z",
     "shell.execute_reply": "2023-04-10T08:35:09.657384Z",
     "shell.execute_reply.started": "2023-04-10T08:35:09.652199Z"
    }
   },
   "outputs": [],
   "source": [
    "# for batch in train_dataloader:\n",
    "#     break\n",
    "# {k: v.shape for k, v in batch.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-10T08:35:09.662106Z",
     "iopub.status.busy": "2023-04-10T08:35:09.661805Z",
     "iopub.status.idle": "2023-04-10T08:35:09.673386Z",
     "shell.execute_reply": "2023-04-10T08:35:09.672468Z",
     "shell.execute_reply.started": "2023-04-10T08:35:09.662065Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "EPOCHS = 1 # changed for model improvement\n",
    "# USE_GPU = torch.cuda.is_available()\n",
    "DROPOUT = .5 # changed for model improvement\n",
    "timestamp = str(int(time.time()))\n",
    "best_dev_acc = 0.0\n",
    "\n",
    "LEARNING_RATE = 1e-5\n",
    "BATCH_SIZE = 128\n",
    "EMBEDDING_TYPE = 'built-in'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-10T08:35:09.676840Z",
     "iopub.status.busy": "2023-04-10T08:35:09.676437Z",
     "iopub.status.idle": "2023-04-10T08:35:20.550641Z",
     "shell.execute_reply": "2023-04-10T08:35:20.549625Z",
     "shell.execute_reply.started": "2023-04-10T08:35:09.676812Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForSequenceClassification: ['lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'lm_head.bias', 'roberta.pooler.dense.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# from transformers import XLMRobertaConfig\n",
    "num_classes = 2\n",
    "\n",
    "# configuration = XLMRobertaConfig(\"xlm-roberta-base\")\n",
    "model = XLMRobertaForSequenceClassification.from_pretrained(\"xlm-roberta-base\",num_labels=num_classes, from_tf=False)\n",
    "\n",
    "# model.to(DEVICE); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-10T08:35:20.552642Z",
     "iopub.status.busy": "2023-04-10T08:35:20.552156Z",
     "iopub.status.idle": "2023-04-10T08:36:02.846812Z",
     "shell.execute_reply": "2023-04-10T08:36:02.845458Z",
     "shell.execute_reply.started": "2023-04-10T08:35:20.552604Z"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "  import lightning.pytorch as pl\n",
    "except:\n",
    "  !pip install tensorboardX lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-10T08:36:13.050692Z",
     "iopub.status.busy": "2023-04-10T08:36:13.050273Z",
     "iopub.status.idle": "2023-04-10T08:36:15.716347Z",
     "shell.execute_reply": "2023-04-10T08:36:15.714601Z",
     "shell.execute_reply.started": "2023-04-10T08:36:13.050648Z"
    }
   },
   "outputs": [],
   "source": [
    "import lightning.pytorch as pl\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import AdamW\n",
    "\n",
    "\n",
    "class LitModel(pl.LightningModule):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.model.train()\n",
    "        self.criteria = nn.CrossEntropyLoss()\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        input = batch[\"input_ids\"].clone().detach().to(self.device)\n",
    "        labels = batch[\"labels\"].clone().detach().to(self.device)\n",
    "        output = self.model(input)\n",
    "        loss = self.criteria(output.logits, labels)\n",
    "\n",
    "        # Compute accuracy\n",
    "        preds = torch.argmax(output.logits, axis=1)\n",
    "        acc = torch.sum(preds == labels).item() / len(labels)\n",
    "\n",
    "        # Log loss and accuracy to TensorBoard\n",
    "        self.logger.log_metrics({\"train_loss\": loss.item(), \"train_acc\": acc}, step=self.global_step)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        input = batch[\"input_ids\"].clone().detach().to(self.device)\n",
    "        labels = batch[\"labels\"].clone().detach().to(self.device)\n",
    "        output = self.model(input)\n",
    "        loss = self.criteria(output.logits, labels)\n",
    "\n",
    "        # Compute accuracy\n",
    "        preds = torch.argmax(output.logits, axis=1)\n",
    "        acc = torch.sum(preds == labels).item() / len(labels)\n",
    "\n",
    "        # Log loss and accuracy to TensorBoard\n",
    "        self.logger.log_metrics({\"val_loss\": loss.item(), \"val_acc\": acc}, step=self.global_step)\n",
    "\n",
    "        return {\"val_loss\": loss.item(), \"val_acc\": acc}\n",
    "        \n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return AdamW(self.model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "    def on_train_end(self):\n",
    "        # Compute accuracy on the validation set\n",
    "        # val_loader = self.trainer.val_dataloader()\n",
    "        self.model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in eval_dataloader:\n",
    "                input = batch[\"input_ids\"].clone().detach().to(self.device)\n",
    "                output = self.model(input)\n",
    "                preds = torch.argmax(output, axis=1)\n",
    "                correct += torch.sum(preds == batch[\"labels\"].clone().detach().to(self.device)).item()\n",
    "                total += len(preds)\n",
    "        val_acc = correct / total\n",
    "\n",
    "        print(f\"Final validation accuracy: {val_acc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-10T08:38:23.233470Z",
     "iopub.status.busy": "2023-04-10T08:38:23.232521Z",
     "iopub.status.idle": "2023-04-10T08:38:23.253290Z",
     "shell.execute_reply": "2023-04-10T08:38:23.252095Z",
     "shell.execute_reply.started": "2023-04-10T08:38:23.233415Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "from lightning.pytorch import Trainer\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "\n",
    "tb_logdir = \"logs-ww-strict\"\n",
    "\n",
    "logger = TensorBoardLogger(tb_logdir, name=\"classifier_model\")\n",
    "trainer = Trainer(logger=logger, max_epochs=EPOCHS,accelerator='gpu', devices='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-10T08:38:25.708651Z",
     "iopub.status.busy": "2023-04-10T08:38:25.708235Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Missing logger folder: logs-ww-strict/classifier_model\n",
      "\n",
      "  | Name     | Type                                | Params\n",
      "-----------------------------------------------------------------\n",
      "0 | model    | XLMRobertaForSequenceClassification | 278 M \n",
      "1 | criteria | CrossEntropyLoss                    | 0     \n",
      "-----------------------------------------------------------------\n",
      "278 M     Trainable params\n",
      "0         Non-trainable params\n",
      "278 M     Total params\n",
      "1,112.181 Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Sanity Checking: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/guneet/opt/miniconda3/envs/bdproj/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/guneet/opt/miniconda3/envs/bdproj/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|                                         | 0/2001 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "trainer.fit(LitModel(model), train_dataloader, eval_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-08T19:48:59.823229Z",
     "iopub.status.busy": "2023-04-08T19:48:59.822236Z",
     "iopub.status.idle": "2023-04-08T19:49:01.738759Z",
     "shell.execute_reply": "2023-04-08T19:49:01.737004Z",
     "shell.execute_reply.started": "2023-04-08T19:48:59.823174Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"roberta_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-08T19:47:47.305121Z",
     "iopub.status.busy": "2023-04-08T19:47:47.303906Z",
     "iopub.status.idle": "2023-04-08T19:47:47.31129Z",
     "shell.execute_reply": "2023-04-08T19:47:47.310018Z",
     "shell.execute_reply.started": "2023-04-08T19:47:47.30507Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-08T19:48:36.358993Z",
     "iopub.status.busy": "2023-04-08T19:48:36.357777Z",
     "iopub.status.idle": "2023-04-08T19:48:36.371121Z",
     "shell.execute_reply": "2023-04-08T19:48:36.369956Z",
     "shell.execute_reply.started": "2023-04-08T19:48:36.358916Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-08T20:00:35.698126Z",
     "iopub.status.busy": "2023-04-08T20:00:35.697501Z",
     "iopub.status.idle": "2023-04-08T20:00:35.706002Z",
     "shell.execute_reply": "2023-04-08T20:00:35.704705Z",
     "shell.execute_reply.started": "2023-04-08T20:00:35.698087Z"
    }
   },
   "outputs": [],
   "source": [
    "def on_train_end_manual(model):\n",
    "        # Compute accuracy on the validation set\n",
    "        # val_loader = self.trainer.val_dataloader()\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in eval_dataloader:\n",
    "                input = batch[\"input_ids\"].clone().detach().to(DEVICE)\n",
    "                output = model(input)\n",
    "                logits = output.logits\n",
    "                preds = torch.argmax(logits, axis=1)\n",
    "                correct += torch.sum(preds == batch[\"labels\"].clone().detach().to(DEVICE)).item()\n",
    "                total += len(preds)\n",
    "                print(correct/total,total)\n",
    "        val_acc = correct / total\n",
    "\n",
    "        print(f\"Final validation accuracy: {val_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-08T20:00:37.467612Z",
     "iopub.status.busy": "2023-04-08T20:00:37.466502Z",
     "iopub.status.idle": "2023-04-08T20:05:45.466486Z",
     "shell.execute_reply": "2023-04-08T20:05:45.465028Z",
     "shell.execute_reply.started": "2023-04-08T20:00:37.467566Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "on_train_end_manual(model.to(DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-08T20:19:13.615629Z",
     "iopub.status.busy": "2023-04-08T20:19:13.615149Z",
     "iopub.status.idle": "2023-04-08T20:19:13.621468Z",
     "shell.execute_reply": "2023-04-08T20:19:13.619959Z",
     "shell.execute_reply.started": "2023-04-08T20:19:13.615583Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer, XLMRobertaForSequenceClassification,DataCollatorWithPadding,XLMRobertaTokenizerFast\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-08T20:22:38.572878Z",
     "iopub.status.busy": "2023-04-08T20:22:38.572409Z",
     "iopub.status.idle": "2023-04-08T20:22:41.160545Z",
     "shell.execute_reply": "2023-04-08T20:22:41.159295Z",
     "shell.execute_reply.started": "2023-04-08T20:22:38.572835Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-08T20:25:35.057726Z",
     "iopub.status.busy": "2023-04-08T20:25:35.056137Z",
     "iopub.status.idle": "2023-04-08T20:25:50.334115Z",
     "shell.execute_reply": "2023-04-08T20:25:50.332361Z",
     "shell.execute_reply.started": "2023-04-08T20:25:35.057653Z"
    }
   },
   "outputs": [],
   "source": [
    "base_model = XLMRobertaForSequenceClassification.from_pretrained(\"xlm-roberta-base\",num_labels=2, force_download=True, from_tf=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-08T20:22:50.906283Z",
     "iopub.status.busy": "2023-04-08T20:22:50.905816Z",
     "iopub.status.idle": "2023-04-08T20:22:54.972541Z",
     "shell.execute_reply": "2023-04-08T20:22:54.971348Z",
     "shell.execute_reply.started": "2023-04-08T20:22:50.906241Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('roberta_model.pt'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-08T20:31:40.810566Z",
     "iopub.status.busy": "2023-04-08T20:31:40.810102Z",
     "iopub.status.idle": "2023-04-08T20:31:42.604903Z",
     "shell.execute_reply": "2023-04-08T20:31:42.603915Z",
     "shell.execute_reply.started": "2023-04-08T20:31:40.810521Z"
    }
   },
   "outputs": [],
   "source": [
    "class ClassPredictor:\n",
    "  def __init__(self,model,tokenizer,model_state):\n",
    "    self.model = model\n",
    "    self.tokenizer = tokenizer\n",
    "    # self.model.load_state_dict(torch.load('/content/drive/MyDrive/roberta_model.pt'))\n",
    "    self.model.load_state_dict(torch.load(model_state))\n",
    "    self.model.eval()\n",
    "\n",
    "  def __call__(self, text, prob=True):\n",
    "    if isinstance(text, str):\n",
    "      text = [text]\n",
    "      unpack = True\n",
    "    else:\n",
    "      unpack = False\n",
    "\n",
    "    tokenized_text = [self.tokenizer.encode(t, add_special_tokens=True) for t in text]\n",
    "    # Pad the tokenized input text to the same length\n",
    "    max_length = max(len(t) for t in tokenized_text)\n",
    "    padded_text = [t + [0] * (max_length - len(t)) for t in tokenized_text]\n",
    "    # Convert the padded input text to PyTorch tensor\n",
    "    input_ids = torch.tensor(padded_text)\n",
    "    # Make predictions with the model\n",
    "    with torch.no_grad():\n",
    "      logits = self.model(input_ids).logits\n",
    "      probs = torch.softmax(logits, dim=1)\n",
    "      print(logits.argmax())\n",
    "        \n",
    "\n",
    "    if prob:\n",
    "      if unpack:\n",
    "        return probs[0,1].tolist()\n",
    "      else:\n",
    "        return probs[:,1].tolist()\n",
    "    else:\n",
    "      return bool(logits.argmax())\n",
    "\n",
    "cp = ClassPredictor(base_model,tokenizer,'roberta_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-08T21:09:22.408381Z",
     "iopub.status.busy": "2023-04-08T21:09:22.407901Z",
     "iopub.status.idle": "2023-04-08T21:09:22.504062Z",
     "shell.execute_reply": "2023-04-08T21:09:22.502632Z",
     "shell.execute_reply.started": "2023-04-08T21:09:22.408337Z"
    }
   },
   "outputs": [],
   "source": [
    "cp(\"I am so sick of life, why are we still here? what is the meaning of it all?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-08T21:09:16.67562Z",
     "iopub.status.busy": "2023-04-08T21:09:16.675117Z",
     "iopub.status.idle": "2023-04-08T21:09:16.799729Z",
     "shell.execute_reply": "2023-04-08T21:09:16.798378Z",
     "shell.execute_reply.started": "2023-04-08T21:09:16.67558Z"
    }
   },
   "outputs": [],
   "source": [
    "cp(\"\"\"Hey guys, did you catch the cannucks' game last night? It was wild. It came down to the wire and\n",
    "   shall go down in history as the greatest game.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Wellness watch",
   "language": "python",
   "name": "bdproj"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
